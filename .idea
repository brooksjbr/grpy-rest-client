# except aiohttp.ClientError as e:
#     print(f"Network error occurred: {e}")
# except json.JSONDecodeError as e:
#     print(f"JSON parsing error: {e}")

# Benefit: Improves reliability by automatically retrying failed requests.

# Add Input Validation
# def validate_url(self, url: str) -> str:
#     if not url.startswith(('http://', 'https://')):
#         raise ValueError("URL must start with http:// or https://")
#     return url.strip("/")

# async_rest_client.py
# Benefit: Early validation prevents runtime errors and improves security.

# Benefit: Safer response handling based on content type prevents parsing errors.

# Implement Request Retries
# from aiohttp import ClientSession, ClientTimeout
# from aiohttp_retry import RetryClient

# async def handle_request(self, retries=3, **kwargs):
#     retry_client = RetryClient(client_session=self.session)
#     response = await retry_client.request(
#         method=self.method,
#         url=self.url,
#         headers=self.headers,
#         retry_attempts=retries,
#         **kwargs,
#     )

# async_rest_client.py
# Benefit: Improves reliability by automatically retrying failed requests.

# Benefit: Prevents requests from hanging indefinitely and provides better control over request lifecycle.

# Implement Session Reuse
# # Add session pool management
# def __init__(self, url: str, method: str = "GET", endpoint: str = "", session: ClientSession = None):
#     self.session = session
#     # ... rest of init


# async_rest_client.py
# Benefit: Reusing sessions improves performance by avoiding connection establishment overhead.

# Add Response Content Type Validation
# async def validate_response(self, response):
#     content_type = response.headers.get('Content-Type', '')
#     if 'application/json' in content_type:
#         return await response.json()
#     return await response.text()

# async_rest_client.py
# Benefit: Safer response handling based on content type prevents parsing errors.

# Implement Request Retries
# from aiohttp import ClientSession, ClientTimeout
# from aiohttp_retry import RetryClient

# async def handle_request(self, retries=3, **kwargs):
#     retry_client = RetryClient(client_session=self.session)
#     response = await retry_client.request(
#         method=self.method,
#         url=self.url,
#         headers=self.headers,
#         retry_attempts=retries,
#         **kwargs,
#     )

# async_rest_client.py
# Benefit: Improves reliability by automatically retrying failed requests.

# The Grpy REST Client is a focused Python library that provides a streamlined way to manage HTTP requests. Its core purpose is to handle REST API interactions efficiently.

# Key aspects:

# Primary functionality centers on making REST HTTP requests
# Includes robust exception handling for common scenarios like:
# Request timeouts
# Connection errors
# Invalid JSON responses
# Server errors
# The project maintains quality through:

# Automated testing (shown by the Tests badge)
# Code quality checks (shown by the Lint badge)
# Comprehensive test coverage for error cases
# The project follows good development practices with:

# Clear setup instructions
# Virtual environment management
# Organized test structure
# Proper CI/CD pipeline integration via GitHub Actions
# It's designed to be a reliable and straightforward tool for developers who need to integrate REST API calls into their Python applications.


# @pytest.mark.asyncio
# async def test_request_parameters(self, mock_client_session):
#     """Test request parameters are correctly passed"""
#     params = {"key": "value"}
#     headers = {"Authorization": "Bearer token"}
#     with patch("aiohttp.ClientSession", return_value=mock_client_session):
#         async with RestClient(TEST_URL, params=params, headers=headers) as client:
#             client.session = mock_client_session  # Add this line to ensure mock is used
#             await client.handle_request()
#             mock_client_session.request.assert_called_with(
#                 method="GET", url=TEST_URL, params=params, headers=headers
#             )

# async with RestClient(
#     url="https://app.ticketmaster.com/discovery/v2/",
#     endpoint="events",
#     params={"apikey": "your-api-key"},
# ) as client:
#     async for events in client.paginate(
#         pagination_params={"page": 0, "size": 20},
#         extract_data_key="_embedded.events",
#     ):
#         for event in events:
#             print(f"Event: {event['name']}")

# @pytest.mark.asyncio
# async def test_paginate_with_request_kwargs(
#     self, client_fixture, mock_response_factory
# ):
#     """Test pagination with additional request kwargs"""
#     # Create response
#     response = mock_response_factory(
#         status=200,
#         json_data={
#             "page": {"number": 1, "totalPages": 1},
#             "data": [{"id": i} for i in range(1, 11)],
#         },
#     )

#     captured_kwargs = []

#     # Create a mock for the session's request method that doesn't conflict with headers
#     async def mock_request(method, url, **kwargs):
#         # Capture all kwargs including method and url
#         captured_kwargs.append({"method": method, "url": url, **kwargs})
#         future = asyncio.Future()
#         future.set_result(response)
#         return future

#     # Replace the client's session with our mock
#     mock_session = MagicMock()
#     mock_session.request = mock_request
#     mock_session.closed = False

#     # Store the original session to restore later
#     original_session = client_fixture.session
#     client_fixture.session = mock_session

#     try:
#         # Call the paginate method with additional kwargs
#         # Don't include headers in request_kwargs to avoid conflict
#         request_kwargs = {"ssl": False}

#         # Instead, update the client's headers directly
#         client_fixture.update_headers({"X-Custom-Header": "test"})

#         async for _ in client_fixture.paginate(
#             data_key="data", request_kwargs=request_kwargs
#         ):
#             pass

#         # Verify the kwargs were passed to request
#         assert len(captured_kwargs) == 1
#         assert captured_kwargs[0]["method"] == "GET"  # Default method
#         assert (
#             captured_kwargs[0]["url"] == "https://api.example.com"
#         )  # Base URL

#         # Check that our custom headers were included
#         assert "headers" in captured_kwargs[0]
#         assert "X-Custom-Header" in captured_kwargs[0]["headers"]
#         assert captured_kwargs[0]["headers"]["X-Custom-Header"] == "test"

#         # Check other custom parameters
#         assert captured_kwargs[0]["ssl"] is False
#         assert captured_kwargs[0]["timeout"] == 30

#     finally:
#         # Restore the original session
#         client_fixture.session = original_session


# @pytest.mark.asyncio
# async def test_paginate_ticketmaster_api(
#     self, client_fixture, mock_response_factory
# ):
#     """Test pagination with Ticketmaster API response format"""
#     # Mock the handle_request method to return predefined responses

#     # First page response
#     first_response = mock_response_factory(
#         status=200,
#         json_data={
#             "page": {
#                 "number": 0,
#                 "size": 20,
#                 "totalElements": 50,
#                 "totalPages": 3,
#             },
#             "events": [{"id": f"event{i}"} for i in range(1, 21)],
#         },
#     )

#     # Second page response
#     second_response = mock_response_factory(
#         status=200,
#         json_data={
#             "page": {
#                 "number": 1,
#                 "size": 20,
#                 "totalElements": 50,
#                 "totalPages": 3,
#             },
#             "events": [{"id": f"event{i}"} for i in range(21, 41)],
#         },
#     )

#     # Third page response
#     third_response = mock_response_factory(
#         status=200,
#         json_data={
#             "page": {
#                 "number": 2,
#                 "size": 20,
#                 "totalElements": 50,
#                 "totalPages": 3,
#             },
#             "events": [{"id": f"event{i}"} for i in range(41, 51)],
#         },
#     )

#     # Create a side effect that returns different responses for each call
#     responses = [first_response, second_response, third_response]

#     with patch.object(
#         client_fixture,
#         "handle_request",
#         side_effect=lambda **kwargs: responses.pop(0),
#     ):
#         # Call the paginate method
#         all_events = []
#         async for page_data in client_fixture.paginate(data_key="events"):
#             all_events.extend(page_data)

#         # Verify we got all events
#         assert len(all_events) == 50
#         assert all_events[0]["id"] == "event1"
#         assert all_events[49]["id"] == "event50"

# @pytest.mark.asyncio
# async def test_paginate_with_max_pages(
#     self, client_fixture, mock_response_factory
# ):
#     """Test pagination with a maximum number of pages"""
#     # Mock the handle_request method to return predefined responses

#     # First page response
#     first_response = mock_response_factory(
#         status=200,
#         json_data={
#             "page": {"number": 1, "totalPages": 5},
#             "data": [{"id": i} for i in range(1, 11)],
#         },
#     )

#     # Second page response
#     second_response = mock_response_factory(
#         status=200,
#         json_data={
#             "page": {"number": 2, "totalPages": 5},
#             "data": [{"id": i} for i in range(11, 21)],
#         },
#     )

#     # Create a side effect that returns different responses for each call
#     responses = [first_response, second_response]

#     with patch.object(
#         client_fixture,
#         "handle_request",
#         side_effect=lambda **kwargs: responses.pop(0),
#     ):
#         # Call the paginate method with max_pages=2
#         all_data = []
#         async for page_data in client_fixture.paginate(
#             data_key="data", max_pages=2
#         ):
#             all_data.extend(page_data)

#         # Verify we only got data from the first 2 pages
#         assert len(all_data) == 20
#         assert all_data[0]["id"] == 1
#         assert all_data[19]["id"] == 20


# 4. Lack of Request Body Handling
# The client doesn't have a dedicated field for request body data, which is essential for POST/PUT/PATCH requests.

# # Add to class definition
# json_data: Optional[Dict[str, Any]] = Field(default_factory=dict)
# data: Optional[Any] = None

# # Then update handle_request to include these
# @handle_exception
# async def handle_request(self, **kwargs):
#     if self.json_data and 'json' not in kwargs:
#         kwargs['json'] = self.json_data
#     if self.data and 'data' not in kwargs:
#         kwargs['data'] = self.data

#     response = await self.session.request(...)

# Copy


# rest_client.py
# Benefit: More convenient API for common REST operations that require request bodies.

# 5. Lack of Type Annotations in Method Parameters
# While the class fields have type annotations, method parameters often don't, which reduces IDE assistance and static type checking benefits.

# # Example improvement
# async def paginate(
#     self,
#     data_key: Optional[str] = None,
#     max_pages: Optional[int] = None,
#     request_kwargs: Optional[Dict[str, Any]] = None
# ) -> AsyncIterator[List[Any]]:

# Copy


# rest_client.py
# Benefit: Better IDE support, static type checking, and self-documentation.

# Summary
# The RestClient implementation generally follows good design principles with a clean async interface and separation of concerns. The code is well-structured with appropriate use of Python's modern features like Pydantic models and async context managers.

# The main opportunities for improvement are around error handling, resource management, and making the API more intuitive for common REST operations. The pagination system could also benefit from refactoring to make it more maintainable and flexible.

# Overall, these improvements would make the client more robust and easier to use correctly, especially for developers who aren't familiar with the codebase.
